{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.linalg import pinv\n",
    "\n",
    "from agents import EmphaticTD, TD\n",
    "from environments import Chain, RandomPolicy\n",
    "from empirical import make_episodes, apply_fa, apply_rfunc, expected_return, learn\n",
    "from features import *\n",
    "from mdptools import *\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set pandas display options\n",
    "pd.set_option('precision', 4)\n",
    "\n",
    "# Set numpy display options\n",
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a series of episodes for a random walk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_states = 7\n",
    "num_episodes = 10000\n",
    "env = Chain(num_states)\n",
    "pol = RandomPolicy(env, random_seed=1010101)\n",
    "raw_episodes = make_episodes(num_episodes, env, pol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant Feature, Constant Reward\n",
    "\n",
    "* r(s) = 1 for s non-terminal\n",
    "* x(s) = 1 for x non-terminal\n",
    "\n",
    "With constant rewards, we effectively calculate the expected number of steps to termination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate expected returns for each state\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{(1,): 4.979989893885801,\n",
       " (2,): 7.969806399839502,\n",
       " (3,): 8.96994327041104,\n",
       " (4,): 7.9439075420942515,\n",
       " (5,): 4.884900741929015}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ETD</th>\n",
       "      <th>TD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weights</th>\n",
       "      <td> [7.6269300441]</td>\n",
       "      <td> [8.9307697443]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ETD              TD\n",
       "weights  [7.6269300441]  [8.9307697443]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Adjust the rewards, apply function approximation\n",
    "phi = Wrap(Bias(), terminals=env.terminals)\n",
    "_rfunc = lambda s, a, sp: 1\n",
    "rfunc = Parameter(_rfunc, terminals=env.terminals)\n",
    "\n",
    "episodes = apply_rfunc(raw_episodes, rfunc)\n",
    "episodes = apply_fa(episodes, phi)\n",
    "\n",
    "# We can check the expected returns for each state \n",
    "print(\"Approximate expected returns for each state\")\n",
    "display(expected_return(apply_rfunc(raw_episodes, rfunc)))\n",
    "\n",
    "# Test the algorithms empirically\n",
    "num_repeats = 10\n",
    "dct = {}\n",
    "\n",
    "# Fixed parameters that (constant for each algorithm)\n",
    "fixed_params = {'gamma': 1.0, 'lmbda': 0.0, 'interest': 1.0,}\n",
    "\n",
    "# The TD solution\n",
    "# param_funcs = {'alpha': Decay(0.99999)}\n",
    "param_funcs = {'alpha': Constant(0.001)}\n",
    "td = TD(len(phi))\n",
    "learn(td, episodes, fixed_params, param_funcs, repeats=num_repeats)\n",
    "\n",
    "# Store information\n",
    "tmp = {'weights': td.theta} \n",
    "dct['TD'] = tmp\n",
    " \n",
    "# The ETD solution\n",
    "param_funcs = {'alpha': Decay(0.99999)}\n",
    "etd = EmphaticTD(len(phi))\n",
    "learn(etd, episodes, fixed_params, param_funcs, repeats=num_repeats)\n",
    "\n",
    "# Store information\n",
    "tmp = {'weights': etd.theta} \n",
    "dct['ETD'] = tmp\n",
    "\n",
    "# Summarize and print information\n",
    "df = pd.DataFrame(dct)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant Reward, Increasing Feature\n",
    "\n",
    "* r(s) = 1 for s non-terminal\n",
    "* x(s) = s+1 for s non-terminal\n",
    "\n",
    "In this case, the analytic solution suggests that ETD will perform worse than TD. \n",
    "We check that actually running the algorithms in these case will behave approximately like the analytic solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytic Solution\n",
    "\n",
    "We analyze a random walk with 5 non-terminal states, starting in state 2 (the middle of the chain), and with parameters defined by\n",
    "\n",
    "$$\\gamma(s) = \\lambda(s) = i(s) = 0 \\quad \\forall s \\text{ terminal}$$\n",
    "\n",
    "For $s$ non-terminal, \n",
    "\n",
    "* $\\gamma(s) = 1$\n",
    "* $\\lambda(s) = 0$\n",
    "* $i(s) = 1$\n",
    "\n",
    "We get the following (asymptopic) solutions:\n",
    "\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>weights</th>\n",
    "      <th>MSE</th>\n",
    "      <th>values</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>Least-Squares</th>\n",
    "      <td> [1.90909090909]</td>\n",
    "      <td> 11.709</td>\n",
    "      <td> [1.90909090909, 3.81818181818, 5.72727272727, ...</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>TD</th>\n",
    "      <td>           [1.8]</td>\n",
    "      <td> 11.840</td>\n",
    "      <td>               [1.8, 3.6, 5.4, 7.2, 9.0, 0.0, 0.0]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>ETD</th>\n",
    "      <td> [1.53333333333]</td>\n",
    "      <td> 13.262</td>\n",
    "      <td> [1.53333333333, 3.06666666667, 4.6, 6.13333333...</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "The true values are:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th>states</th>\n",
    "      <th>true values</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td> 1</td>\n",
    "      <td> 5</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td> 2</td>\n",
    "      <td> 8</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td> 3</td>\n",
    "      <td> 9</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td> 4</td>\n",
    "      <td> 8</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td> 5</td>\n",
    "      <td> 5</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td> 0</td>\n",
    "      <td> 0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td> 6</td>\n",
    "      <td> 0</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate expected returns for each state\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{(1,): 4.979989893885801,\n",
       " (2,): 7.969806399839502,\n",
       " (3,): 8.96994327041104,\n",
       " (4,): 7.9439075420942515,\n",
       " (5,): 4.884900741929015}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up the experiment\n",
    "phi = Wrap(Identity(1), terminals=env.terminals)\n",
    "_rfunc = lambda s, a, sp: 1\n",
    "rfunc = Parameter(_rfunc, terminals=env.terminals)\n",
    "\n",
    "episodes = apply_rfunc(raw_episodes, rfunc)\n",
    "episodes = apply_fa(episodes, phi)\n",
    "\n",
    "# We can check the expected returns for each state\n",
    "print(\"Approximate expected returns for each state\")\n",
    "display(expected_return(apply_rfunc(raw_episodes, rfunc)))\n",
    "\n",
    "# We check that the feature function behaves as expected\n",
    "for s in env.states:\n",
    "    print(s, phi(s))\n",
    "\n",
    "# Test the algorithms empirically\n",
    "num_repeats = 10\n",
    "dct = {}\n",
    "\n",
    "# Fixed parameters that (constant for each algorithm)\n",
    "fixed_params = {'gamma': 1.0, 'lmbda': 0.0, 'interest': 1.0}\n",
    "\n",
    "# The TD solution\n",
    "param_funcs = {'alpha': Decay(0.99999)}\n",
    "td = TD(len(phi))\n",
    "learn(td, episodes, fixed_params, param_funcs, repeats=num_repeats)\n",
    "\n",
    "# Store information\n",
    "tmp = {'weights': td.theta} \n",
    "dct['TD'] = tmp\n",
    " \n",
    "# The ETD solution\n",
    "param_funcs = {'alpha': Decay(0.99999)}\n",
    "etd = EmphaticTD(len(phi))\n",
    "learn(etd, episodes, fixed_params, param_funcs, repeats=num_repeats)\n",
    "\n",
    "# Store information\n",
    "tmp = {'weights': etd.theta} \n",
    "dct['ETD'] = tmp\n",
    "\n",
    "# Summarize and print information\n",
    "df = pd.DataFrame(dct)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is approximately what we derived through the analytic method, so unless I have managed to make the same kind of mistake in both implementations TD indeed outperforms ETD in this particular setting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
